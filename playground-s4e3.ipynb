{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ddeddf",
   "metadata": {
    "papermill": {
     "duration": 0.005683,
     "end_time": "2024-03-19T15:40:52.560675",
     "exception": false,
     "start_time": "2024-03-19T15:40:52.554992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Playground S4E3 - Steel Plate Defect Prediction\n",
    "\n",
    "Author: [shpatrickguo](https://www.kaggle.com/shpatrickguo)\n",
    "\n",
    "The goal of the notebook is to predict the probability of various defects on steel plate. The dataset for this competition (both train and test) was generated from a deep learning model trained on the [Steel Plates Faults dataset](https://archive.ics.uci.edu/dataset/198/steel+plates+faults) from UCI. Individual AUC scores are calculated for each different categorical class, and then averaged together to get an overall AUC score. \n",
    "\n",
    "There are 7 different types of defects that can occur in steel plates:\n",
    "\n",
    "- `Pastry`\n",
    "- `Z_Scratch`\n",
    "- `K_Scatch`\n",
    "- `Stains`\n",
    "- `Dirtiness`\n",
    "- `Bumps`\n",
    "- `Other_Faults`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bca6de",
   "metadata": {
    "papermill": {
     "duration": 0.005445,
     "end_time": "2024-03-19T15:40:52.571185",
     "exception": false,
     "start_time": "2024-03-19T15:40:52.565740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf344bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:40:52.583387Z",
     "iopub.status.busy": "2024-03-19T15:40:52.582810Z",
     "iopub.status.idle": "2024-03-19T15:41:04.785175Z",
     "shell.execute_reply": "2024-03-19T15:41:04.783744Z"
    },
    "papermill": {
     "duration": 12.211219,
     "end_time": "2024-03-19T15:41:04.787589",
     "exception": false,
     "start_time": "2024-03-19T15:40:52.576370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install extra packages\n",
    "!pip install lazypredict -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e17952",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-19T15:41:04.799933Z",
     "iopub.status.busy": "2024-03-19T15:41:04.799593Z",
     "iopub.status.idle": "2024-03-19T15:41:10.135212Z",
     "shell.execute_reply": "2024-03-19T15:41:10.134157Z"
    },
    "papermill": {
     "duration": 5.345262,
     "end_time": "2024-03-19T15:41:10.138127",
     "exception": false,
     "start_time": "2024-03-19T15:41:04.792865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a6706b",
   "metadata": {
    "papermill": {
     "duration": 0.005266,
     "end_time": "2024-03-19T15:41:10.148840",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.143574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data\n",
    "\n",
    "1. Location Features:\n",
    "    - `X_Minimum`: The minimum x-coordinate of the fault.\n",
    "    - `X_Maximum`: The maximum x-coordinate of the fault.\n",
    "    - `Y_Minimum`: The minimum y-coordinate of the fault.\n",
    "    - `Y_Maximum`: The maximum y-coordinate of the fault.\n",
    "2. Size Features:\n",
    "    - `Pixels_Areas`: Area of the fault in pixels.\n",
    "    - `X_Perimeter`: Perimeter along the x-axis of the fault.\n",
    "    - `Y_Perimeter`: Perimeter along the y-axis of the fault.\n",
    "3. Luminosity Features:\n",
    "    - `Sum_of_Luminosity`: Sum of luminosity values in the fault area.\n",
    "    - `Minimum_of_Luminosity`: Minimum luminosity value in the fault area.\n",
    "    - `Maximum_of_Luminosity`: Maximum luminosity value in the fault area.\n",
    "4. Material and Index Features:\n",
    "    - `TypeOfSteel_A300`: Type of steel (A300).\n",
    "    - `TypeOfSteel_A400`: Type of steel (A400).\n",
    "    - `Steel_Plate_Thickness`: Thickness of the steel plate.\n",
    "    - `Edges_Index`, `Empty_Index`, `Square_Index`, `Outside_X_Index`, `Edges_X_Index`, `Edges_Y_Index`, `Outside_Global_Index`: Various index values related to edges and geometry.\n",
    "5. Logarithmic Features:\n",
    "    - `LogOfAreas`: Logarithm of the area of the fault.\n",
    "    - `Log_X_Index`, `Log_Y_Index`: Logarithmic indices related to X and Y coordinates.\n",
    "6. Statistical Features:\n",
    "    - `Orientation_Index`: Index describing orientation.\n",
    "    - `Luminosity_Index`: Index related to luminosity.\n",
    "    - `SigmoidOfAreas`: Sigmoid function applied to areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9726931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:41:10.160511Z",
     "iopub.status.busy": "2024-03-19T15:41:10.159964Z",
     "iopub.status.idle": "2024-03-19T15:41:10.336403Z",
     "shell.execute_reply": "2024-03-19T15:41:10.335302Z"
    },
    "papermill": {
     "duration": 0.184681,
     "end_time": "2024-03-19T15:41:10.338657",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.153976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s4e3/train.csv')\n",
    "faults = pd.read_csv('/kaggle/input/faulty-steel-plates/faults.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s4e3/test.csv')\n",
    "sample_submission = pd.read_csv('/kaggle/input/playground-series-s4e3/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899dbe23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T07:14:00.667052Z",
     "iopub.status.busy": "2024-03-04T07:14:00.665585Z",
     "iopub.status.idle": "2024-03-04T07:14:12.998228Z",
     "shell.execute_reply": "2024-03-04T07:14:12.996918Z",
     "shell.execute_reply.started": "2024-03-04T07:14:00.667002Z"
    },
    "papermill": {
     "duration": 0.005579,
     "end_time": "2024-03-19T15:41:10.349399",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.343820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering and Selection\n",
    "\n",
    "Feature generation adapted from https://www.kaggle.com/competitions/playground-series-s4e3/discussion/481687 by [Ivan Zadorozniy](https://www.kaggle.com/ivanzadorozniy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c21fc6ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:41:10.360733Z",
     "iopub.status.busy": "2024-03-19T15:41:10.360378Z",
     "iopub.status.idle": "2024-03-19T15:41:10.395948Z",
     "shell.execute_reply": "2024-03-19T15:41:10.394735Z"
    },
    "papermill": {
     "duration": 0.043843,
     "end_time": "2024-03-19T15:41:10.398213",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.354370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define target classes\n",
    "target_classes = [\"Pastry\", \"Z_Scratch\", \"K_Scatch\", \"Stains\", \"Dirtiness\", \"Bumps\", \"Other_Faults\"]\n",
    "\n",
    "# Remove 'id' column from train and test DataFrames\n",
    "train.drop(\"id\", axis=1, inplace=True)\n",
    "test.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "# Calculate the sum of target classes for each row\n",
    "row_sums = train[target_classes].sum(axis=1)\n",
    "\n",
    "# Filter out rows where the sum is greater than 1 or equal to 0\n",
    "filtered_train = train[(row_sums > 0) & (row_sums <= 1)]\n",
    "\n",
    "# Specify if dataset is synthetically generated\n",
    "train['generated'] = 1\n",
    "faults['generated'] = 0\n",
    "test['generated'] = 1\n",
    "\n",
    "# Concatenate faults DataFrame with train DataFrame\n",
    "train = pd.concat([train, faults], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = train.drop(target_classes, axis=1)\n",
    "y = train[target_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de85a87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:41:10.409578Z",
     "iopub.status.busy": "2024-03-19T15:41:10.409218Z",
     "iopub.status.idle": "2024-03-19T15:41:10.455769Z",
     "shell.execute_reply": "2024-03-19T15:41:10.454449Z"
    },
    "papermill": {
     "duration": 0.054734,
     "end_time": "2024-03-19T15:41:10.458228",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.403494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    epsilon = 1e-6  # A small constant to avoid division by zero or taking the logarithm of zero\n",
    "    \n",
    "    # Location Features\n",
    "    data['X_Distance'] = data['X_Maximum'] - data['X_Minimum']\n",
    "    data['Y_Distance'] = data['Y_Maximum'] - data['Y_Minimum']\n",
    "\n",
    "    # Density Feature\n",
    "    data['Density'] = data['Pixels_Areas'] / (data['X_Perimeter'] + data['Y_Perimeter'] + epsilon)\n",
    "\n",
    "    # Relative Perimeter Feature\n",
    "    data['Relative_Perimeter'] = data['X_Perimeter'] / (data['X_Perimeter'] + data['Y_Perimeter'] + epsilon)\n",
    "\n",
    "    # Circularity Feature\n",
    "    data['Circularity'] = data['Pixels_Areas'] / (data['X_Perimeter'] ** 2 + epsilon)\n",
    "\n",
    "    # Symmetry Index Feature\n",
    "    data['Symmetry_Index'] = np.abs(data['X_Distance'] - data['Y_Distance']) / (data['X_Distance'] + data['Y_Distance'] + epsilon)\n",
    "\n",
    "    # Color Contrast Feature\n",
    "    data['Color_Contrast'] = data['Maximum_of_Luminosity'] - data['Minimum_of_Luminosity']\n",
    "\n",
    "    # Combined Geometric Index Feature\n",
    "    data['Combined_Geometric_Index'] = data['Edges_Index'] * data['Square_Index']\n",
    "\n",
    "    # Interaction Term Feature\n",
    "    data['X_Distance*Pixels_Areas'] = data['X_Distance'] * data['Pixels_Areas']\n",
    "\n",
    "    # Additional Features\n",
    "    data['sin_orientation'] = np.sin(data['Orientation_Index'])\n",
    "    data['Edges_Index2'] = np.exp(data['Edges_Index'] + epsilon)\n",
    "    data['X_Maximum2'] = np.sin(data['X_Maximum'])\n",
    "    data['Y_Minimum2'] = np.sin(data['Y_Minimum'])\n",
    "    data['Aspect_Ratio_Pixels'] = np.where(data['Y_Perimeter'] == 0, 0, data['X_Perimeter'] / (data['Y_Perimeter'] + epsilon))\n",
    "    data['Aspect_Ratio'] = np.where(data['Y_Distance'] == 0, 0, data['X_Distance'] / (data['Y_Distance'] + epsilon))\n",
    "\n",
    "    # Average Luminosity Feature\n",
    "    data['Average_Luminosity'] = (data['Sum_of_Luminosity'] + data['Minimum_of_Luminosity']) / 2\n",
    "\n",
    "    # Normalized Steel Thickness Feature\n",
    "    data['Normalized_Steel_Thickness'] = (data['Steel_Plate_Thickness'] - data['Steel_Plate_Thickness'].min()) / (data['Steel_Plate_Thickness'].max() - data['Steel_Plate_Thickness'].min())\n",
    "\n",
    "    # Logarithmic Features\n",
    "    data['Log_Perimeter'] = np.log(data['X_Perimeter'] + data['Y_Perimeter'] + epsilon)\n",
    "    data['Log_Luminosity'] = np.log(data['Sum_of_Luminosity'] + epsilon)\n",
    "    data['Log_Aspect_Ratio'] = np.log(data['Aspect_Ratio'] ** 2 + epsilon)\n",
    "\n",
    "    # Statistical Features\n",
    "    data['Combined_Index'] = data['Orientation_Index'] * data['Luminosity_Index']\n",
    "    data['Sigmoid_Areas'] = 1 / (1 + np.exp(-data['LogOfAreas'] + epsilon))\n",
    "\n",
    "    return data\n",
    "\n",
    "X = preprocess_data(X)\n",
    "test = preprocess_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5375bcfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:41:10.470530Z",
     "iopub.status.busy": "2024-03-19T15:41:10.470136Z",
     "iopub.status.idle": "2024-03-19T15:41:10.486774Z",
     "shell.execute_reply": "2024-03-19T15:41:10.485737Z"
    },
    "papermill": {
     "duration": 0.025685,
     "end_time": "2024-03-19T15:41:10.489087",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.463402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_cols = ['TypeOfSteel_A300', 'TypeOfSteel_A400', 'Outside_Global_Index', 'generated']\n",
    "# Convert columns to object dtype\n",
    "X[cat_cols] = X[cat_cols].astype('category')\n",
    "test[cat_cols] = test[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "189ba03d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:41:10.500510Z",
     "iopub.status.busy": "2024-03-19T15:41:10.500175Z",
     "iopub.status.idle": "2024-03-19T15:41:10.530806Z",
     "shell.execute_reply": "2024-03-19T15:41:10.529701Z"
    },
    "papermill": {
     "duration": 0.038679,
     "end_time": "2024-03-19T15:41:10.532900",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.494221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_to_scale = [\n",
    "    'X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n",
    "    'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity', 'Minimum_of_Luminosity',\n",
    "    'Maximum_of_Luminosity', 'Length_of_Conveyer', 'Steel_Plate_Thickness',\n",
    "    'X_Distance', 'Y_Distance', 'Density', 'Circularity', 'Symmetry_Index',\n",
    "    'Color_Contrast', 'X_Distance*Pixels_Areas', 'Aspect_Ratio_Pixels',\n",
    "    'Aspect_Ratio', 'Average_Luminosity'\n",
    "]\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X[features_to_scale])\n",
    "X[features_to_scale] = scaler.transform(X[features_to_scale])\n",
    "test[features_to_scale] = scaler.transform(test[features_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfa6407",
   "metadata": {
    "papermill": {
     "duration": 0.005338,
     "end_time": "2024-03-19T15:41:10.543581",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.538243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01db1771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:41:10.554576Z",
     "iopub.status.busy": "2024-03-19T15:41:10.554246Z",
     "iopub.status.idle": "2024-03-19T15:41:10.563087Z",
     "shell.execute_reply": "2024-03-19T15:41:10.562191Z"
    },
    "papermill": {
     "duration": 0.017,
     "end_time": "2024-03-19T15:41:10.565263",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.548263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor target in target_classes:\\n    print(f\"Lazy predict for target class: {target}\")\\n    print(\"*\" * 80)\\n\\n    # Splitting dataset into training and testing part\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X,\\n        y[target],\\n        test_size=0.3,\\n        random_state=42,\\n        stratify=y[target], \\n        shuffle=True\\n    )\\n    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\\n    models, predictions = clf.fit(X_train, X_test, y_train, y_test)\\n    print(models)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for target in target_classes:\n",
    "    print(f\"Lazy predict for target class: {target}\")\n",
    "    print(\"*\" * 80)\n",
    "\n",
    "    # Splitting dataset into training and testing part\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y[target],\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=y[target], \n",
    "        shuffle=True\n",
    "    )\n",
    "    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "    models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "    print(models)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c5cf8",
   "metadata": {
    "papermill": {
     "duration": 0.00482,
     "end_time": "2024-03-19T15:41:10.575440",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.570620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1231c6e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:41:10.587179Z",
     "iopub.status.busy": "2024-03-19T15:41:10.586849Z",
     "iopub.status.idle": "2024-03-19T15:41:10.593786Z",
     "shell.execute_reply": "2024-03-19T15:41:10.593051Z"
    },
    "papermill": {
     "duration": 0.015199,
     "end_time": "2024-03-19T15:41:10.595897",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.580698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%capture\\n# Define dictionaries to store best hyperparameters and ROC AUC values\\nbest_params_xgb = {}\\nbest_auc_xgb = {}\\nbest_params_lgb = {}\\nbest_auc_lgb = {}\\n\\n# Iterate over each target class\\nfor target_class in target_classes:\\n    print(f\"Tuning hyperparameters for {target_class}...\")\\n\\n    # Split the data into train and validation sets for the current target class\\n    X_train, X_val, y_train, y_val = train_test_split(X, y[target_class], test_size=0.2, random_state=42, stratify=y[target_class], shuffle=True)\\n    \\n    # Define the objective function for hyperparameter optimization for XGBoost\\n    def objective_xgb(trial):\\n        params = {\\n            \"objective\": \"binary:logistic\",\\n            \"n_estimators\": 1000,\\n            \"verbosity\": 0,\\n            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\\n            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\\n            \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\\n            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\\n            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\\n            \"enable_categorical\": True\\n        }\\n\\n        model = xgb.XGBClassifier(**params)\\n        model.fit(X_train, y_train, verbose=False)\\n        predictions = model.predict_proba(X_val)[:, 1]  # Predict probabilities for the positive class\\n        roc_auc = roc_auc_score(y_val, predictions)\\n        return roc_auc\\n\\n    # Perform hyperparameter optimization using Optuna for XGBoost\\n    study_xgb = optuna.create_study(direction=\\'maximize\\')  # Change direction to \\'maximize\\'\\n    study_xgb.optimize(objective_xgb, n_trials=30)\\n    # Store the best hyperparameters and ROC AUC for XGBoost\\n    best_params_xgb[target_class] = study_xgb.best_params\\n    best_auc_xgb[target_class] = study_xgb.best_value\\n    \\n    # Define the objective function for hyperparameter optimization for LightGBM\\n    def objective_lgb(trial):\\n        params = {\\n            \"objective\": \"binary\",\\n            \"metric\": \"auc\",\\n            \"n_estimators\": 1000,\\n            \"bagging_freq\": 1,\\n            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\\n            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\\n            \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\\n            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\\n            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\\n            \"enable_categorical\": True\\n        }\\n\\n        model = lgb.LGBMClassifier(**params)\\n        model.fit(X_train, y_train)\\n        predictions = model.predict_proba(X_val)[:, 1]  # Predict probabilities for the positive class\\n        roc_auc = roc_auc_score(y_val, predictions)\\n        return roc_auc\\n\\n    # Perform hyperparameter optimization using Optuna for LightGBM\\n    study_lgb = optuna.create_study(direction=\\'maximize\\')  # Change direction to \\'maximize\\'\\n    study_lgb.optimize(objective_lgb, n_trials=30)\\n    # Store the best hyperparameters and ROC AUC for LightGBM\\n    best_params_lgb[target_class] = study_lgb.best_params\\n    best_auc_lgb[target_class] = study_lgb.best_value\\n    \\n# Save the dictionaries to JSON files\\nwith open(\\'best_params_xgb.json\\', \\'w\\') as f:\\n    json.dump(best_params_xgb, f)\\n\\nwith open(\\'best_auc_xgb.json\\', \\'w\\') as f:\\n    json.dump(best_auc_xgb, f)\\n\\nwith open(\\'best_params_lgb.json\\', \\'w\\') as f:\\n    json.dump(best_params_lgb, f)\\n\\nwith open(\\'best_auc_lgb.json\\', \\'w\\') as f:\\n    json.dump(best_auc_lgb, f)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%capture\n",
    "# Define dictionaries to store best hyperparameters and ROC AUC values\n",
    "best_params_xgb = {}\n",
    "best_auc_xgb = {}\n",
    "best_params_lgb = {}\n",
    "best_auc_lgb = {}\n",
    "\n",
    "# Iterate over each target class\n",
    "for target_class in target_classes:\n",
    "    print(f\"Tuning hyperparameters for {target_class}...\")\n",
    "\n",
    "    # Split the data into train and validation sets for the current target class\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y[target_class], test_size=0.2, random_state=42, stratify=y[target_class], shuffle=True)\n",
    "    \n",
    "    # Define the objective function for hyperparameter optimization for XGBoost\n",
    "    def objective_xgb(trial):\n",
    "        params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"n_estimators\": 1000,\n",
    "            \"verbosity\": 0,\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
    "            \"enable_categorical\": True\n",
    "        }\n",
    "\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "        predictions = model.predict_proba(X_val)[:, 1]  # Predict probabilities for the positive class\n",
    "        roc_auc = roc_auc_score(y_val, predictions)\n",
    "        return roc_auc\n",
    "\n",
    "    # Perform hyperparameter optimization using Optuna for XGBoost\n",
    "    study_xgb = optuna.create_study(direction='maximize')  # Change direction to 'maximize'\n",
    "    study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "    # Store the best hyperparameters and ROC AUC for XGBoost\n",
    "    best_params_xgb[target_class] = study_xgb.best_params\n",
    "    best_auc_xgb[target_class] = study_xgb.best_value\n",
    "    \n",
    "    # Define the objective function for hyperparameter optimization for LightGBM\n",
    "    def objective_lgb(trial):\n",
    "        params = {\n",
    "            \"objective\": \"binary\",\n",
    "            \"metric\": \"auc\",\n",
    "            \"n_estimators\": 1000,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "            \"enable_categorical\": True\n",
    "        }\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict_proba(X_val)[:, 1]  # Predict probabilities for the positive class\n",
    "        roc_auc = roc_auc_score(y_val, predictions)\n",
    "        return roc_auc\n",
    "\n",
    "    # Perform hyperparameter optimization using Optuna for LightGBM\n",
    "    study_lgb = optuna.create_study(direction='maximize')  # Change direction to 'maximize'\n",
    "    study_lgb.optimize(objective_lgb, n_trials=30)\n",
    "    # Store the best hyperparameters and ROC AUC for LightGBM\n",
    "    best_params_lgb[target_class] = study_lgb.best_params\n",
    "    best_auc_lgb[target_class] = study_lgb.best_value\n",
    "    \n",
    "# Save the dictionaries to JSON files\n",
    "with open('best_params_xgb.json', 'w') as f:\n",
    "    json.dump(best_params_xgb, f)\n",
    "\n",
    "with open('best_auc_xgb.json', 'w') as f:\n",
    "    json.dump(best_auc_xgb, f)\n",
    "\n",
    "with open('best_params_lgb.json', 'w') as f:\n",
    "    json.dump(best_params_lgb, f)\n",
    "\n",
    "with open('best_auc_lgb.json', 'w') as f:\n",
    "    json.dump(best_auc_lgb, f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb90d949",
   "metadata": {
    "papermill": {
     "duration": 0.004775,
     "end_time": "2024-03-19T15:41:10.606062",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.601287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3e3859b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:41:10.617823Z",
     "iopub.status.busy": "2024-03-19T15:41:10.617513Z",
     "iopub.status.idle": "2024-03-19T15:41:10.628240Z",
     "shell.execute_reply": "2024-03-19T15:41:10.627476Z"
    },
    "papermill": {
     "duration": 0.018772,
     "end_time": "2024-03-19T15:41:10.630095",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.611323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params_xgb = {\n",
    "    'Pastry': {\n",
    "        'learning_rate': 0.006926977447202338,\n",
    "        'max_depth': 8,\n",
    "        'subsample': 0.4940484982010708,\n",
    "        'colsample_bytree': 0.2387416720485505,\n",
    "        'min_child_weight': 7\n",
    "    },\n",
    "    'Z_Scratch': {\n",
    "        'learning_rate': 0.004986245704292724,\n",
    "        'max_depth': 7,\n",
    "        'subsample': 0.9332436730077105,\n",
    "        'colsample_bytree': 0.48907554356577143,\n",
    "        'min_child_weight': 8\n",
    "    },\n",
    "    'K_Scatch': {\n",
    "        'learning_rate': 0.012033749117039628,\n",
    "        'max_depth': 3,\n",
    "        'subsample': 0.7325661464279343,\n",
    "        'colsample_bytree': 0.12231748494766136,\n",
    "        'min_child_weight': 11\n",
    "    },\n",
    "    'Stains': {\n",
    "        'learning_rate': 0.006196927928720472,\n",
    "        'max_depth': 4,\n",
    "        'subsample': 0.8534492089576168,\n",
    "        'colsample_bytree': 0.3761987501528039,\n",
    "        'min_child_weight': 12\n",
    "    },\n",
    "    'Dirtiness': {\n",
    "        'learning_rate': 0.006031795590671394,\n",
    "        'max_depth': 8,\n",
    "        'subsample': 0.9258644109322758,\n",
    "        'colsample_bytree': 0.19262200620009873,\n",
    "        'min_child_weight': 1\n",
    "    },\n",
    "    'Bumps': {\n",
    "        'learning_rate': 0.030511454287023506,\n",
    "        'max_depth': 3,\n",
    "        'subsample': 0.9894325575143829,\n",
    "        'colsample_bytree': 0.2691197048033656,\n",
    "        'min_child_weight': 14\n",
    "    },\n",
    "    'Other_Faults': {\n",
    "        'learning_rate': 0.005695980576574583,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.7415198064018484,\n",
    "        'colsample_bytree': 0.22189734386288398,\n",
    "        'min_child_weight': 10\n",
    "    }\n",
    "}\n",
    "\n",
    "best_params_lgb = {\n",
    "    'Pastry': {\n",
    "        'learning_rate': 0.005838510189618896,\n",
    "        'num_leaves': 413,\n",
    "        'subsample': 0.668486759118746,\n",
    "        'colsample_bytree': 0.32125270364553377,\n",
    "        'min_data_in_leaf': 82\n",
    "    },\n",
    "    'Z_Scratch': {\n",
    "        'learning_rate': 0.0028573346654447536,\n",
    "        'num_leaves': 969,\n",
    "        'subsample': 0.8069989336666283,\n",
    "        'colsample_bytree': 0.5920712547068819,\n",
    "        'min_data_in_leaf': 94\n",
    "    },\n",
    "    'K_Scatch': {\n",
    "        'learning_rate': 0.0010011424770011905,\n",
    "        'num_leaves': 878,\n",
    "        'subsample': 0.8805178529367013,\n",
    "        'colsample_bytree': 0.3669661156317522,\n",
    "        'min_data_in_leaf': 28\n",
    "    },\n",
    "    'Stains': {\n",
    "        'learning_rate': 0.0035045365968749084,\n",
    "        'num_leaves': 684,\n",
    "        'subsample': 0.7679208745010446,\n",
    "        'colsample_bytree': 0.32902244287866944,\n",
    "        'min_data_in_leaf': 21\n",
    "    },\n",
    "    'Dirtiness': {\n",
    "        'learning_rate': 0.005251331571844952,\n",
    "        'num_leaves': 258,\n",
    "        'subsample': 0.6080883184894392,\n",
    "        'colsample_bytree': 0.6583700658822181,\n",
    "        'min_data_in_leaf': 24\n",
    "    },\n",
    "    'Bumps': {\n",
    "        'learning_rate': 0.0056976290404213105,\n",
    "        'num_leaves': 1001,\n",
    "        'subsample': 0.36947216922049836,\n",
    "        'colsample_bytree': 0.673006584019963,\n",
    "        'min_data_in_leaf': 54\n",
    "    },\n",
    "    'Other_Faults': {\n",
    "        'learning_rate': 0.0031447823170776255,\n",
    "        'num_leaves': 366,\n",
    "        'subsample': 0.991229746792238,\n",
    "        'colsample_bytree': 0.3250828708107952,\n",
    "        'min_data_in_leaf': 79\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b3f7e7",
   "metadata": {
    "papermill": {
     "duration": 0.004821,
     "end_time": "2024-03-19T15:41:10.640253",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.635432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "277c7972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:41:10.653335Z",
     "iopub.status.busy": "2024-03-19T15:41:10.652937Z",
     "iopub.status.idle": "2024-03-19T15:41:35.325096Z",
     "shell.execute_reply": "2024-03-19T15:41:35.324069Z"
    },
    "papermill": {
     "duration": 24.682338,
     "end_time": "2024-03-19T15:41:35.327504",
     "exception": false,
     "start_time": "2024-03-19T15:41:10.645166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "def train_xgb_model(X_train, X_test, y_train, y_test, params):\n",
    "    # Initialize XGBoost classifier with given parameters\n",
    "    xgb_model = XGBClassifier(**params)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities for the positive class on the test data\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    return xgb_model, roc_auc\n",
    "\n",
    "def train_lgb_model(X_train, X_test, y_train, y_test, params):\n",
    "    # Initialize LightGBM classifier with given parameters\n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities for the positive class on the test data\n",
    "    y_pred_proba = lgb_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    return lgb_model, roc_auc\n",
    "\n",
    "# Define a dictionary to store the trained models and their ROC AUC scores\n",
    "models = {}\n",
    "\n",
    "# Train models for each target class\n",
    "for target_class in target_classes:\n",
    "    print(f\"Training models for {target_class}...\")\n",
    "\n",
    "    # Get best parameters for XGBoost and LightGBM for the current target class\n",
    "    best_params_xgb_target = best_params_xgb.get(target_class, {})\n",
    "    best_params_xgb_target['enable_categorical'] = True\n",
    "    best_params_lgb_target = best_params_lgb.get(target_class, {})\n",
    "    best_params_lgb_target['enable_categorical'] = True\n",
    "\n",
    "    # Split the data into train and test sets for the current target class\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y[target_class], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train XGBoost model for the current target class\n",
    "    xgb_model, xgb_roc_auc = train_xgb_model(X_train, X_test, y_train, y_test, best_params_xgb_target)\n",
    "    print(f\"XGBoost ROC AUC for {target_class}: {xgb_roc_auc}\")\n",
    "\n",
    "    # Train LightGBM model for the current target class\n",
    "    lgb_model, lgb_roc_auc = train_lgb_model(X_train, X_test, y_train, y_test, best_params_lgb_target)\n",
    "    print(f\"LightGBM ROC AUC for {target_class}: {lgb_roc_auc}\")\n",
    "\n",
    "    # Store the trained models and their ROC AUC scores in the dictionary\n",
    "    models[target_class] = {'xgb_model': xgb_model, 'xgb_roc_auc': xgb_roc_auc,\n",
    "                             'lgb_model': lgb_model, 'lgb_roc_auc': lgb_roc_auc}\n",
    "\n",
    "# Calculate weights based on ROC AUC scores\n",
    "weights = {}\n",
    "for target_class in target_classes:\n",
    "    xgb_weight = models[target_class]['xgb_roc_auc'] / (models[target_class]['xgb_roc_auc'] + models[target_class]['lgb_roc_auc'])\n",
    "    lgb_weight = 1 - xgb_weight\n",
    "    weights[target_class] = {'xgb': xgb_weight, 'lgb': lgb_weight}\n",
    "\n",
    "# Ensemble the models\n",
    "ensemble_models = {}\n",
    "for target_class in target_classes:\n",
    "    xgb_model = models[target_class]['xgb_model']\n",
    "    lgb_model = models[target_class]['lgb_model']\n",
    "    ensemble_model = VotingClassifier(estimators=[('xgb', xgb_model), ('lgb', lgb_model)], \n",
    "                                      voting='soft', \n",
    "                                      weights=[weights[target_class]['xgb'], weights[target_class]['lgb']])\n",
    "    ensemble_models[target_class] = ensemble_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a8e93a",
   "metadata": {
    "papermill": {
     "duration": 0.004847,
     "end_time": "2024-03-19T15:41:35.337687",
     "exception": false,
     "start_time": "2024-03-19T15:41:35.332840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dcac9ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:41:35.349885Z",
     "iopub.status.busy": "2024-03-19T15:41:35.349537Z",
     "iopub.status.idle": "2024-03-19T15:42:06.872037Z",
     "shell.execute_reply": "2024-03-19T15:42:06.871086Z"
    },
    "papermill": {
     "duration": 31.531359,
     "end_time": "2024-03-19T15:42:06.874283",
     "exception": false,
     "start_time": "2024-03-19T15:41:35.342924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Define a dictionary to store the predictions for each target class\n",
    "predictions = {}\n",
    "\n",
    "# Predict on test data using ensemble models\n",
    "for target_class in target_classes:\n",
    "    ensemble_model = ensemble_models[target_class]  # Get the ensemble model for the current target class\n",
    "    ensemble_model.fit(X, y[target_class])\n",
    "    y_pred_proba = ensemble_model.predict_proba(test)[:, 1]  # Predict probabilities for the positive class\n",
    "    predictions[target_class] = y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c692a",
   "metadata": {
    "papermill": {
     "duration": 0.005442,
     "end_time": "2024-03-19T15:42:06.885776",
     "exception": false,
     "start_time": "2024-03-19T15:42:06.880334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d42559d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:42:06.897982Z",
     "iopub.status.busy": "2024-03-19T15:42:06.897603Z",
     "iopub.status.idle": "2024-03-19T15:42:07.016705Z",
     "shell.execute_reply": "2024-03-19T15:42:07.015864Z"
    },
    "papermill": {
     "duration": 0.127765,
     "end_time": "2024-03-19T15:42:07.019082",
     "exception": false,
     "start_time": "2024-03-19T15:42:06.891317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19219</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19220</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19221</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19222</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19223</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Pastry  Z_Scratch  K_Scatch  Stains  Dirtiness  Bumps  Other_Faults\n",
       "0  19219    0.23       0.07      0.12    0.05       0.06   0.20          0.35\n",
       "1  19220    0.18       0.08      0.13    0.05       0.09   0.20          0.34\n",
       "2  19221    0.06       0.08      0.13    0.05       0.05   0.28          0.38\n",
       "3  19222    0.11       0.07      0.12    0.05       0.05   0.34          0.36\n",
       "4  19223    0.07       0.07      0.12    0.05       0.05   0.44          0.36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(predictions)\n",
    "submission.insert(0, \"id\", sample_submission[\"id\"])\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66a7687",
   "metadata": {
    "papermill": {
     "duration": 0.005306,
     "end_time": "2024-03-19T15:42:07.030276",
     "exception": false,
     "start_time": "2024-03-19T15:42:07.024970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7659021,
     "sourceId": 68699,
     "sourceType": "competition"
    },
    {
     "datasetId": 2363,
     "sourceId": 3972,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 78.071488,
   "end_time": "2024-03-19T15:42:07.957494",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-19T15:40:49.886006",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
