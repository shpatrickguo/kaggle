{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795d2f3f",
   "metadata": {
    "papermill": {
     "duration": 0.010962,
     "end_time": "2024-03-24T06:18:47.968381",
     "exception": false,
     "start_time": "2024-03-24T06:18:47.957419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Playground S4E3 - Steel Plate Defect Prediction\n",
    "\n",
    "Author: [shpatrickguo](https://www.kaggle.com/shpatrickguo)\n",
    "\n",
    "The goal of the notebook is to predict the probability of various defects on steel plate. The dataset for this competition (both train and test) was generated from a deep learning model trained on the [Steel Plates Faults dataset](https://archive.ics.uci.edu/dataset/198/steel+plates+faults) from UCI. Individual AUC scores are calculated for each different categorical class, and then averaged together to get an overall AUC score. \n",
    "\n",
    "There are 7 different types of defects that can occur in steel plates:\n",
    "\n",
    "- `Pastry`\n",
    "- `Z_Scratch`\n",
    "- `K_Scatch`\n",
    "- `Stains`\n",
    "- `Dirtiness`\n",
    "- `Bumps`\n",
    "- `Other_Faults`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570be7c0",
   "metadata": {
    "papermill": {
     "duration": 0.01045,
     "end_time": "2024-03-24T06:18:47.989340",
     "exception": false,
     "start_time": "2024-03-24T06:18:47.978890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "109541cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:18:48.013267Z",
     "iopub.status.busy": "2024-03-24T06:18:48.012784Z",
     "iopub.status.idle": "2024-03-24T06:19:05.886342Z",
     "shell.execute_reply": "2024-03-24T06:19:05.884321Z"
    },
    "papermill": {
     "duration": 17.890517,
     "end_time": "2024-03-24T06:19:05.889772",
     "exception": false,
     "start_time": "2024-03-24T06:18:47.999255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install extra packages\n",
    "!pip install lazypredict -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50e56b9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:05.919947Z",
     "iopub.status.busy": "2024-03-24T06:19:05.919123Z",
     "iopub.status.idle": "2024-03-24T06:19:14.892439Z",
     "shell.execute_reply": "2024-03-24T06:19:14.890810Z"
    },
    "papermill": {
     "duration": 8.993858,
     "end_time": "2024-03-24T06:19:14.895720",
     "exception": false,
     "start_time": "2024-03-24T06:19:05.901862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "from sklearn.inspection import permutation_importance\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf32fb",
   "metadata": {
    "papermill": {
     "duration": 0.010176,
     "end_time": "2024-03-24T06:19:14.916064",
     "exception": false,
     "start_time": "2024-03-24T06:19:14.905888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data\n",
    "\n",
    "1. Location Features:\n",
    "    - `X_Minimum`: The minimum x-coordinate of the fault.\n",
    "    - `X_Maximum`: The maximum x-coordinate of the fault.\n",
    "    - `Y_Minimum`: The minimum y-coordinate of the fault.\n",
    "    - `Y_Maximum`: The maximum y-coordinate of the fault.\n",
    "2. Size Features:\n",
    "    - `Pixels_Areas`: Area of the fault in pixels.\n",
    "    - `X_Perimeter`: Perimeter along the x-axis of the fault.\n",
    "    - `Y_Perimeter`: Perimeter along the y-axis of the fault.\n",
    "3. Luminosity Features:\n",
    "    - `Sum_of_Luminosity`: Sum of luminosity values in the fault area.\n",
    "    - `Minimum_of_Luminosity`: Minimum luminosity value in the fault area.\n",
    "    - `Maximum_of_Luminosity`: Maximum luminosity value in the fault area.\n",
    "4. Material and Index Features:\n",
    "    - `TypeOfSteel_A300`: Type of steel (A300).\n",
    "    - `TypeOfSteel_A400`: Type of steel (A400).\n",
    "    - `Steel_Plate_Thickness`: Thickness of the steel plate.\n",
    "    - `Edges_Index`, `Empty_Index`, `Square_Index`, `Outside_X_Index`, `Edges_X_Index`, `Edges_Y_Index`, `Outside_Global_Index`: Various index values related to edges and geometry.\n",
    "5. Logarithmic Features:\n",
    "    - `LogOfAreas`: Logarithm of the area of the fault.\n",
    "    - `Log_X_Index`, `Log_Y_Index`: Logarithmic indices related to X and Y coordinates.\n",
    "6. Statistical Features:\n",
    "    - `Orientation_Index`: Index describing orientation.\n",
    "    - `Luminosity_Index`: Index related to luminosity.\n",
    "    - `SigmoidOfAreas`: Sigmoid function applied to areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adf07dbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:14.938791Z",
     "iopub.status.busy": "2024-03-24T06:19:14.938005Z",
     "iopub.status.idle": "2024-03-24T06:19:15.253913Z",
     "shell.execute_reply": "2024-03-24T06:19:15.252851Z"
    },
    "papermill": {
     "duration": 0.330744,
     "end_time": "2024-03-24T06:19:15.257182",
     "exception": false,
     "start_time": "2024-03-24T06:19:14.926438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s4e3/train.csv')\n",
    "faults = pd.read_csv('/kaggle/input/faulty-steel-plates/faults.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s4e3/test.csv')\n",
    "sample_submission = pd.read_csv('/kaggle/input/playground-series-s4e3/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab5215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T07:14:00.667052Z",
     "iopub.status.busy": "2024-03-04T07:14:00.665585Z",
     "iopub.status.idle": "2024-03-04T07:14:12.998228Z",
     "shell.execute_reply": "2024-03-04T07:14:12.996918Z",
     "shell.execute_reply.started": "2024-03-04T07:14:00.667002Z"
    },
    "papermill": {
     "duration": 0.010191,
     "end_time": "2024-03-24T06:19:15.278471",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.268280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature generation adapted from https://www.kaggle.com/competitions/playground-series-s4e3/discussion/481687 by [Ivan Zadorozniy](https://www.kaggle.com/ivanzadorozniy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe0c437f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:15.303523Z",
     "iopub.status.busy": "2024-03-24T06:19:15.302264Z",
     "iopub.status.idle": "2024-03-24T06:19:15.373068Z",
     "shell.execute_reply": "2024-03-24T06:19:15.371400Z"
    },
    "papermill": {
     "duration": 0.087446,
     "end_time": "2024-03-24T06:19:15.376456",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.289010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define target classes\n",
    "target_classes = [\"Pastry\", \"Z_Scratch\", \"K_Scatch\", \"Stains\", \"Dirtiness\", \"Bumps\", \"Other_Faults\"]\n",
    "\n",
    "# Remove 'id' column from train and test DataFrames\n",
    "train.drop(\"id\", axis=1, inplace=True)\n",
    "test.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "# Calculate the sum of target classes for each row\n",
    "row_sums = train[target_classes].sum(axis=1)\n",
    "\n",
    "# Filter out rows where the sum is greater than 1 or equal to 0\n",
    "filtered_train = train[(row_sums > 0) & (row_sums <= 1)]\n",
    "\n",
    "# Specify if dataset is synthetically generated\n",
    "train['generated'] = 1\n",
    "faults['generated'] = 0\n",
    "test['generated'] = 1\n",
    "\n",
    "# Concatenate faults DataFrame with train DataFrame\n",
    "train = pd.concat([train, faults], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = train.drop(target_classes, axis=1)\n",
    "y = train[target_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8e035b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:15.401563Z",
     "iopub.status.busy": "2024-03-24T06:19:15.401130Z",
     "iopub.status.idle": "2024-03-24T06:19:15.468870Z",
     "shell.execute_reply": "2024-03-24T06:19:15.466816Z"
    },
    "papermill": {
     "duration": 0.083188,
     "end_time": "2024-03-24T06:19:15.471897",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.388709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_features(data):\n",
    "    epsilon = 1e-6  # A small constant to avoid division by zero or taking the logarithm of zero\n",
    "    \n",
    "    # Location Features\n",
    "    data['X_Distance'] = data['X_Maximum'] - data['X_Minimum']\n",
    "    data['Y_Distance'] = data['Y_Maximum'] - data['Y_Minimum']\n",
    "\n",
    "    # Density Feature\n",
    "    data['Density'] = data['Pixels_Areas'] / (data['X_Perimeter'] + data['Y_Perimeter'] + epsilon)\n",
    "\n",
    "    # Relative Perimeter Feature\n",
    "    data['Relative_Perimeter'] = data['X_Perimeter'] / (data['X_Perimeter'] + data['Y_Perimeter'] + epsilon)\n",
    "\n",
    "    # Circularity Feature\n",
    "    data['Circularity'] = data['Pixels_Areas'] / (data['X_Perimeter'] ** 2 + epsilon)\n",
    "\n",
    "    # Symmetry Index Feature\n",
    "    data['Symmetry_Index'] = np.abs(data['X_Distance'] - data['Y_Distance']) / (data['X_Distance'] + data['Y_Distance'] + epsilon)\n",
    "\n",
    "    # Color Contrast Feature\n",
    "    data['Color_Contrast'] = data['Maximum_of_Luminosity'] - data['Minimum_of_Luminosity']\n",
    "\n",
    "    # Combined Geometric Index Feature\n",
    "    data['Combined_Geometric_Index'] = data['Edges_Index'] * data['Square_Index']\n",
    "\n",
    "    # Interaction Term Feature\n",
    "    data['X_Distance*Pixels_Areas'] = data['X_Distance'] * data['Pixels_Areas']\n",
    "\n",
    "    # Additional Features\n",
    "    data['sin_orientation'] = np.sin(data['Orientation_Index'])\n",
    "    data['Edges_Index2'] = np.exp(data['Edges_Index'] + epsilon)\n",
    "    data['X_Maximum2'] = np.sin(data['X_Maximum'])\n",
    "    data['Y_Minimum2'] = np.sin(data['Y_Minimum'])\n",
    "    data['Aspect_Ratio_Pixels'] = np.where(data['Y_Perimeter'] == 0, 0, data['X_Perimeter'] / (data['Y_Perimeter'] + epsilon))\n",
    "    data['Aspect_Ratio'] = np.where(data['Y_Distance'] == 0, 0, data['X_Distance'] / (data['Y_Distance'] + epsilon))\n",
    "\n",
    "    # Average Luminosity Feature\n",
    "    data['Average_Luminosity'] = (data['Sum_of_Luminosity'] + data['Minimum_of_Luminosity']) / 2\n",
    "\n",
    "    # Normalized Steel Thickness Feature\n",
    "    data['Normalized_Steel_Thickness'] = (data['Steel_Plate_Thickness'] - data['Steel_Plate_Thickness'].min()) / (data['Steel_Plate_Thickness'].max() - data['Steel_Plate_Thickness'].min())\n",
    "\n",
    "    # Logarithmic Features\n",
    "    data['Log_Perimeter'] = np.log(data['X_Perimeter'] + data['Y_Perimeter'] + epsilon)\n",
    "    data['Log_Luminosity'] = np.log(data['Sum_of_Luminosity'] + epsilon)\n",
    "    data['Log_Aspect_Ratio'] = np.log(data['Aspect_Ratio'] ** 2 + epsilon)\n",
    "\n",
    "    # Statistical Features\n",
    "    data['Combined_Index'] = data['Orientation_Index'] * data['Luminosity_Index']\n",
    "    data['Sigmoid_Areas'] = 1 / (1 + np.exp(-data['LogOfAreas'] + epsilon))\n",
    "\n",
    "    return data\n",
    "\n",
    "X = generate_features(X)\n",
    "test = generate_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f619f46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:15.494211Z",
     "iopub.status.busy": "2024-03-24T06:19:15.493804Z",
     "iopub.status.idle": "2024-03-24T06:19:15.514488Z",
     "shell.execute_reply": "2024-03-24T06:19:15.512929Z"
    },
    "papermill": {
     "duration": 0.036021,
     "end_time": "2024-03-24T06:19:15.517879",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.481858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_cols = ['TypeOfSteel_A300', 'TypeOfSteel_A400', 'Outside_Global_Index', 'generated']\n",
    "# Convert columns to object dtype\n",
    "X[cat_cols] = X[cat_cols].astype('category')\n",
    "test[cat_cols] = test[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18903de6",
   "metadata": {
    "papermill": {
     "duration": 0.009778,
     "end_time": "2024-03-24T06:19:15.538026",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.528248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d5b760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:15.560954Z",
     "iopub.status.busy": "2024-03-24T06:19:15.560470Z",
     "iopub.status.idle": "2024-03-24T06:19:15.757834Z",
     "shell.execute_reply": "2024-03-24T06:19:15.756138Z"
    },
    "papermill": {
     "duration": 0.212803,
     "end_time": "2024-03-24T06:19:15.761076",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.548273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped column: TypeOfSteel_A400, Correlated to: TypeOfSteel_A300, Correlation coefficient: 0.9979390823770107\n",
      "Dropped column: X_Minimum, Correlated to: X_Maximum, Correlation coefficient: 0.989682979661914\n",
      "Dropped column: sin_orientation, Correlated to: Orientation_Index, Correlation coefficient: 0.9992870031386843\n",
      "Dropped column: Edges_Index2, Correlated to: Edges_Index, Correlation coefficient: 0.9934093935302362\n",
      "Dropped column: Log_Luminosity, Correlated to: LogOfAreas, Correlation coefficient: 0.9716250377331292\n",
      "Dropped column: Sum_of_Luminosity, Correlated to: Average_Luminosity, Correlation coefficient: 0.9999999985943983\n",
      "Dropped column: Steel_Plate_Thickness, Correlated to: Normalized_Steel_Thickness, Correlation coefficient: 0.9999999999999988\n",
      "Dropped column: Y_Minimum, Correlated to: Y_Maximum, Correlation coefficient: 0.9720417278216671\n",
      "Dropped column: Log_Perimeter, Correlated to: LogOfAreas, Correlation coefficient: 0.96363945583183\n"
     ]
    }
   ],
   "source": [
    "def remove_highly_correlated_features(df_train, df_test, threshold=0.95):\n",
    "    # Compute the correlation matrix for the training set\n",
    "    corr_matrix_train = df_train.corr().abs()\n",
    "    \n",
    "    # Exclude the main diagonal\n",
    "    np.fill_diagonal(corr_matrix_train.values, 0)\n",
    "    \n",
    "    # Create a mask for features with high correlation in the training set\n",
    "    mask_train = corr_matrix_train > threshold\n",
    "    \n",
    "    # Find the index of features to drop in the training set\n",
    "    features_to_drop = set()\n",
    "    for col in mask_train.columns:\n",
    "        correlated_cols = list(mask_train.index[mask_train[col]])\n",
    "        for correlated_col in correlated_cols:\n",
    "            if col < correlated_col:  # Only keep one of the correlated features\n",
    "                features_to_drop.add(correlated_col)\n",
    "    \n",
    "    # Print out the dropped columns and the columns they were correlated to\n",
    "    for col in features_to_drop:\n",
    "        correlated_cols = list(mask_train.index[mask_train[col]])\n",
    "        corr_values = list(corr_matrix_train.loc[mask_train[col], col])\n",
    "        for i, correlated_col in enumerate(correlated_cols):\n",
    "            print(f\"Dropped column: {col}, Correlated to: {correlated_col}, Correlation coefficient: {corr_values[i]}\")\n",
    "    \n",
    "    # Drop highly correlated features from both training and test sets\n",
    "    df_train_filtered = df_train.drop(columns=features_to_drop)\n",
    "    df_test_filtered = df_test.drop(columns=features_to_drop)\n",
    "    \n",
    "    return df_train_filtered, df_test_filtered\n",
    "\n",
    "X, test = remove_highly_correlated_features(X, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25beed14",
   "metadata": {
    "papermill": {
     "duration": 0.011022,
     "end_time": "2024-03-24T06:19:15.782925",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.771903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212c1384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:15.806032Z",
     "iopub.status.busy": "2024-03-24T06:19:15.805601Z",
     "iopub.status.idle": "2024-03-24T06:19:15.844581Z",
     "shell.execute_reply": "2024-03-24T06:19:15.843389Z"
    },
    "papermill": {
     "duration": 0.054507,
     "end_time": "2024-03-24T06:19:15.848009",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.793502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_to_scale = [\n",
    "    'X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n",
    "    'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity', 'Minimum_of_Luminosity',\n",
    "    'Maximum_of_Luminosity', 'Length_of_Conveyer', 'Steel_Plate_Thickness',\n",
    "    'X_Distance', 'Y_Distance', 'Density', 'Circularity', 'Symmetry_Index',\n",
    "    'Color_Contrast', 'X_Distance*Pixels_Areas', 'Aspect_Ratio_Pixels',\n",
    "    'Aspect_Ratio', 'Average_Luminosity'\n",
    "]\n",
    "\n",
    "# Filter features to scale based on the remaining columns in the DataFrame\n",
    "features_to_scale = [col for col in features_to_scale if col in X.columns]\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X[features_to_scale])\n",
    "X[features_to_scale] = scaler.transform(X[features_to_scale])\n",
    "test[features_to_scale] = scaler.transform(test[features_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a3ed5",
   "metadata": {
    "papermill": {
     "duration": 0.010238,
     "end_time": "2024-03-24T06:19:15.868960",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.858722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06f6be52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:15.892490Z",
     "iopub.status.busy": "2024-03-24T06:19:15.892082Z",
     "iopub.status.idle": "2024-03-24T06:19:15.902588Z",
     "shell.execute_reply": "2024-03-24T06:19:15.901006Z"
    },
    "papermill": {
     "duration": 0.025642,
     "end_time": "2024-03-24T06:19:15.905432",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.879790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor target in target_classes:\\n    print(f\"Lazy predict for target class: {target}\")\\n    print(\"*\" * 80)\\n\\n    # Splitting dataset into training and testing part\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X,\\n        y[target],\\n        test_size=0.3,\\n        random_state=42,\\n        stratify=y[target], \\n        shuffle=True\\n    )\\n    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\\n    models, predictions = clf.fit(X_train, X_test, y_train, y_test)\\n    print(models)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for target in target_classes:\n",
    "    print(f\"Lazy predict for target class: {target}\")\n",
    "    print(\"*\" * 80)\n",
    "\n",
    "    # Splitting dataset into training and testing part\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y[target],\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=y[target], \n",
    "        shuffle=True\n",
    "    )\n",
    "    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "    models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "    print(models)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c1d2b",
   "metadata": {
    "papermill": {
     "duration": 0.011175,
     "end_time": "2024-03-24T06:19:15.929126",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.917951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45e5aafc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:15.955114Z",
     "iopub.status.busy": "2024-03-24T06:19:15.954689Z",
     "iopub.status.idle": "2024-03-24T06:19:15.968583Z",
     "shell.execute_reply": "2024-03-24T06:19:15.967025Z"
    },
    "papermill": {
     "duration": 0.030787,
     "end_time": "2024-03-24T06:19:15.971707",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.940920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%capture\\n# Define dictionaries to store best hyperparameters and ROC AUC values\\nbest_params_xgb = {}\\nbest_auc_xgb = {}\\nbest_params_lgb = {}\\nbest_auc_lgb = {}\\n\\n# Iterate over each target class\\nfor target_class in target_classes:\\n    print(f\"Tuning hyperparameters for {target_class}...\")\\n\\n    # Split the data into train and validation sets for the current target class\\n    X_train, X_val, y_train, y_val = train_test_split(X, y[target_class], test_size=0.2, random_state=42, stratify=y[target_class], shuffle=True)\\n    \\n    # Define the objective function for hyperparameter optimization for XGBoost\\n    def objective_xgb(trial):\\n        params = {\\n            \"objective\": \"binary:logistic\",\\n            \"n_estimators\": 1000,\\n            \"verbosity\": 0,\\n            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\\n            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\\n            \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\\n            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\\n            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\\n            \"enable_categorical\": True\\n        }\\n\\n        model = xgb.XGBClassifier(**params)\\n        model.fit(X_train, y_train, verbose=False)\\n        predictions = model.predict_proba(X_val)[:, 1]  # Predict probabilities for the positive class\\n        roc_auc = roc_auc_score(y_val, predictions)\\n        return roc_auc\\n\\n    # Perform hyperparameter optimization using Optuna for XGBoost\\n    study_xgb = optuna.create_study(direction=\\'maximize\\')  # Change direction to \\'maximize\\'\\n    study_xgb.optimize(objective_xgb, n_trials=30)\\n    # Store the best hyperparameters and ROC AUC for XGBoost\\n    best_params_xgb[target_class] = study_xgb.best_params\\n    best_auc_xgb[target_class] = study_xgb.best_value\\n    \\n    # Define the objective function for hyperparameter optimization for LightGBM\\n    def objective_lgb(trial):\\n        params = {\\n            \"objective\": \"binary\",\\n            \"metric\": \"auc\",\\n            \"n_estimators\": 1000,\\n            \"bagging_freq\": 1,\\n            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\\n            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\\n            \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\\n            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\\n            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\\n            \"enable_categorical\": True\\n        }\\n\\n        model = lgb.LGBMClassifier(**params)\\n        model.fit(X_train, y_train)\\n        predictions = model.predict_proba(X_val)[:, 1]  # Predict probabilities for the positive class\\n        roc_auc = roc_auc_score(y_val, predictions)\\n        return roc_auc\\n\\n    # Perform hyperparameter optimization using Optuna for LightGBM\\n    study_lgb = optuna.create_study(direction=\\'maximize\\')  # Change direction to \\'maximize\\'\\n    study_lgb.optimize(objective_lgb, n_trials=30)\\n    # Store the best hyperparameters and ROC AUC for LightGBM\\n    best_params_lgb[target_class] = study_lgb.best_params\\n    best_auc_lgb[target_class] = study_lgb.best_value\\n    \\n# Save the dictionaries to JSON files\\nwith open(\\'best_params_xgb.json\\', \\'w\\') as f:\\n    json.dump(best_params_xgb, f)\\n\\nwith open(\\'best_auc_xgb.json\\', \\'w\\') as f:\\n    json.dump(best_auc_xgb, f)\\n\\nwith open(\\'best_params_lgb.json\\', \\'w\\') as f:\\n    json.dump(best_params_lgb, f)\\n\\nwith open(\\'best_auc_lgb.json\\', \\'w\\') as f:\\n    json.dump(best_auc_lgb, f)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%capture\n",
    "# Define dictionaries to store best hyperparameters and ROC AUC values\n",
    "best_params_xgb = {}\n",
    "best_auc_xgb = {}\n",
    "best_params_lgb = {}\n",
    "best_auc_lgb = {}\n",
    "\n",
    "# Iterate over each target class\n",
    "for target_class in target_classes:\n",
    "    print(f\"Tuning hyperparameters for {target_class}...\")\n",
    "\n",
    "    # Split the data into train and validation sets for the current target class\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y[target_class], test_size=0.2, random_state=42, stratify=y[target_class], shuffle=True)\n",
    "    \n",
    "    # Define the objective function for hyperparameter optimization for XGBoost\n",
    "    def objective_xgb(trial):\n",
    "        params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"n_estimators\": 1000,\n",
    "            \"verbosity\": 0,\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
    "            \"enable_categorical\": True\n",
    "        }\n",
    "\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "        predictions = model.predict_proba(X_val)[:, 1]  # Predict probabilities for the positive class\n",
    "        roc_auc = roc_auc_score(y_val, predictions)\n",
    "        return roc_auc\n",
    "\n",
    "    # Perform hyperparameter optimization using Optuna for XGBoost\n",
    "    study_xgb = optuna.create_study(direction='maximize')  # Change direction to 'maximize'\n",
    "    study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "    # Store the best hyperparameters and ROC AUC for XGBoost\n",
    "    best_params_xgb[target_class] = study_xgb.best_params\n",
    "    best_auc_xgb[target_class] = study_xgb.best_value\n",
    "    \n",
    "    # Define the objective function for hyperparameter optimization for LightGBM\n",
    "    def objective_lgb(trial):\n",
    "        params = {\n",
    "            \"objective\": \"binary\",\n",
    "            \"metric\": \"auc\",\n",
    "            \"n_estimators\": 1000,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "            \"enable_categorical\": True\n",
    "        }\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict_proba(X_val)[:, 1]  # Predict probabilities for the positive class\n",
    "        roc_auc = roc_auc_score(y_val, predictions)\n",
    "        return roc_auc\n",
    "\n",
    "    # Perform hyperparameter optimization using Optuna for LightGBM\n",
    "    study_lgb = optuna.create_study(direction='maximize')  # Change direction to 'maximize'\n",
    "    study_lgb.optimize(objective_lgb, n_trials=30)\n",
    "    # Store the best hyperparameters and ROC AUC for LightGBM\n",
    "    best_params_lgb[target_class] = study_lgb.best_params\n",
    "    best_auc_lgb[target_class] = study_lgb.best_value\n",
    "    \n",
    "# Save the dictionaries to JSON files\n",
    "with open('best_params_xgb.json', 'w') as f:\n",
    "    json.dump(best_params_xgb, f)\n",
    "\n",
    "with open('best_auc_xgb.json', 'w') as f:\n",
    "    json.dump(best_auc_xgb, f)\n",
    "\n",
    "with open('best_params_lgb.json', 'w') as f:\n",
    "    json.dump(best_params_lgb, f)\n",
    "\n",
    "with open('best_auc_lgb.json', 'w') as f:\n",
    "    json.dump(best_auc_lgb, f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76cfe3e",
   "metadata": {
    "papermill": {
     "duration": 0.010533,
     "end_time": "2024-03-24T06:19:15.993167",
     "exception": false,
     "start_time": "2024-03-24T06:19:15.982634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a200fa39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:16.020358Z",
     "iopub.status.busy": "2024-03-24T06:19:16.019853Z",
     "iopub.status.idle": "2024-03-24T06:19:16.038072Z",
     "shell.execute_reply": "2024-03-24T06:19:16.036521Z"
    },
    "papermill": {
     "duration": 0.034011,
     "end_time": "2024-03-24T06:19:16.041049",
     "exception": false,
     "start_time": "2024-03-24T06:19:16.007038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params_xgb = {\n",
    "    'Pastry': {\n",
    "        'learning_rate': 0.006926977447202338,\n",
    "        'max_depth': 8,\n",
    "        'subsample': 0.4940484982010708,\n",
    "        'colsample_bytree': 0.2387416720485505,\n",
    "        'min_child_weight': 7\n",
    "    },\n",
    "    'Z_Scratch': {\n",
    "        'learning_rate': 0.004986245704292724,\n",
    "        'max_depth': 7,\n",
    "        'subsample': 0.9332436730077105,\n",
    "        'colsample_bytree': 0.48907554356577143,\n",
    "        'min_child_weight': 8\n",
    "    },\n",
    "    'K_Scatch': {\n",
    "        'learning_rate': 0.012033749117039628,\n",
    "        'max_depth': 3,\n",
    "        'subsample': 0.7325661464279343,\n",
    "        'colsample_bytree': 0.12231748494766136,\n",
    "        'min_child_weight': 11\n",
    "    },\n",
    "    'Stains': {\n",
    "        'learning_rate': 0.006196927928720472,\n",
    "        'max_depth': 4,\n",
    "        'subsample': 0.8534492089576168,\n",
    "        'colsample_bytree': 0.3761987501528039,\n",
    "        'min_child_weight': 12\n",
    "    },\n",
    "    'Dirtiness': {\n",
    "        'learning_rate': 0.006031795590671394,\n",
    "        'max_depth': 8,\n",
    "        'subsample': 0.9258644109322758,\n",
    "        'colsample_bytree': 0.19262200620009873,\n",
    "        'min_child_weight': 1\n",
    "    },\n",
    "    'Bumps': {\n",
    "        'learning_rate': 0.030511454287023506,\n",
    "        'max_depth': 3,\n",
    "        'subsample': 0.9894325575143829,\n",
    "        'colsample_bytree': 0.2691197048033656,\n",
    "        'min_child_weight': 14\n",
    "    },\n",
    "    'Other_Faults': {\n",
    "        'learning_rate': 0.005695980576574583,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.7415198064018484,\n",
    "        'colsample_bytree': 0.22189734386288398,\n",
    "        'min_child_weight': 10\n",
    "    }\n",
    "}\n",
    "\n",
    "best_params_lgb = {\n",
    "    'Pastry': {\n",
    "        'learning_rate': 0.005838510189618896,\n",
    "        'num_leaves': 413,\n",
    "        'subsample': 0.668486759118746,\n",
    "        'colsample_bytree': 0.32125270364553377,\n",
    "        'min_data_in_leaf': 82\n",
    "    },\n",
    "    'Z_Scratch': {\n",
    "        'learning_rate': 0.0028573346654447536,\n",
    "        'num_leaves': 969,\n",
    "        'subsample': 0.8069989336666283,\n",
    "        'colsample_bytree': 0.5920712547068819,\n",
    "        'min_data_in_leaf': 94\n",
    "    },\n",
    "    'K_Scatch': {\n",
    "        'learning_rate': 0.0010011424770011905,\n",
    "        'num_leaves': 878,\n",
    "        'subsample': 0.8805178529367013,\n",
    "        'colsample_bytree': 0.3669661156317522,\n",
    "        'min_data_in_leaf': 28\n",
    "    },\n",
    "    'Stains': {\n",
    "        'learning_rate': 0.0035045365968749084,\n",
    "        'num_leaves': 684,\n",
    "        'subsample': 0.7679208745010446,\n",
    "        'colsample_bytree': 0.32902244287866944,\n",
    "        'min_data_in_leaf': 21\n",
    "    },\n",
    "    'Dirtiness': {\n",
    "        'learning_rate': 0.005251331571844952,\n",
    "        'num_leaves': 258,\n",
    "        'subsample': 0.6080883184894392,\n",
    "        'colsample_bytree': 0.6583700658822181,\n",
    "        'min_data_in_leaf': 24\n",
    "    },\n",
    "    'Bumps': {\n",
    "        'learning_rate': 0.0056976290404213105,\n",
    "        'num_leaves': 1001,\n",
    "        'subsample': 0.36947216922049836,\n",
    "        'colsample_bytree': 0.673006584019963,\n",
    "        'min_data_in_leaf': 54\n",
    "    },\n",
    "    'Other_Faults': {\n",
    "        'learning_rate': 0.0031447823170776255,\n",
    "        'num_leaves': 366,\n",
    "        'subsample': 0.991229746792238,\n",
    "        'colsample_bytree': 0.3250828708107952,\n",
    "        'min_data_in_leaf': 79\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab0eea",
   "metadata": {
    "papermill": {
     "duration": 0.010713,
     "end_time": "2024-03-24T06:19:16.062314",
     "exception": false,
     "start_time": "2024-03-24T06:19:16.051601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfcb8958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:16.090008Z",
     "iopub.status.busy": "2024-03-24T06:19:16.089470Z",
     "iopub.status.idle": "2024-03-24T06:19:16.104946Z",
     "shell.execute_reply": "2024-03-24T06:19:16.103308Z"
    },
    "papermill": {
     "duration": 0.035106,
     "end_time": "2024-03-24T06:19:16.108543",
     "exception": false,
     "start_time": "2024-03-24T06:19:16.073437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%capture\\ndef train_xgb_model(X_train, X_test, y_train, y_test, params):\\n    # Initialize XGBoost classifier with given parameters\\n    xgb_model = XGBClassifier(**params)\\n    \\n    # Train the model on the training data\\n    xgb_model.fit(X_train, y_train)\\n    \\n    # Predict probabilities for the positive class on the test data\\n    y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\\n    \\n    # Calculate ROC AUC score\\n    roc_auc = roc_auc_score(y_test, y_pred_proba)\\n    \\n    return xgb_model, roc_auc\\n\\ndef train_lgb_model(X_train, X_test, y_train, y_test, params):\\n    # Initialize LightGBM classifier with given parameters\\n    lgb_model = LGBMClassifier(**params)\\n    \\n    # Train the model on the training data\\n    lgb_model.fit(X_train, y_train)\\n    \\n    # Predict probabilities for the positive class on the test data\\n    y_pred_proba = lgb_model.predict_proba(X_test)[:, 1]\\n    \\n    # Calculate ROC AUC score\\n    roc_auc = roc_auc_score(y_test, y_pred_proba)\\n    \\n    return lgb_model, roc_auc\\n\\n# Define a dictionary to store the trained models and their ROC AUC scores\\nmodels = {}\\n\\n# Train models for each target class\\nfor target_class in target_classes:\\n    print(f\"Training models for {target_class}...\")\\n\\n    # Get best parameters for XGBoost and LightGBM for the current target class\\n    best_params_xgb_target = best_params_xgb.get(target_class, {})\\n    best_params_xgb_target[\\'enable_categorical\\'] = True\\n    best_params_lgb_target = best_params_lgb.get(target_class, {})\\n    best_params_lgb_target[\\'enable_categorical\\'] = True\\n\\n    # Initialize RepeatedStratifiedKFold\\n    kf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)\\n    \\n    # Initialize lists to store the scores for each fold\\n    xgb_roc_auc_scores = []\\n    lgb_roc_auc_scores = []\\n\\n    # Split the data using StratifiedKFold\\n    for train_index, test_index in kf.split(X, y[target_class]):\\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\\n        y_train, y_test = y[target_class].iloc[train_index], y[target_class].iloc[test_index]\\n\\n        # Train XGBoost model for the current target class\\n        xgb_model, xgb_roc_auc = train_xgb_model(X_train, X_test, y_train, y_test, best_params_xgb_target)\\n        xgb_roc_auc_scores.append(xgb_roc_auc)\\n\\n        # Train LightGBM model for the current target class\\n        lgb_model, lgb_roc_auc = train_lgb_model(X_train, X_test, y_train, y_test, best_params_lgb_target)\\n        lgb_roc_auc_scores.append(lgb_roc_auc)\\n\\n    # Calculate the mean ROC AUC scores across all folds\\n    mean_xgb_roc_auc = np.mean(xgb_roc_auc_scores)\\n    mean_lgb_roc_auc = np.mean(lgb_roc_auc_scores)\\n\\n    print(f\"Mean XGBoost ROC AUC for {target_class}: {mean_xgb_roc_auc}\")\\n    print(f\"Mean LightGBM ROC AUC for {target_class}: {mean_lgb_roc_auc}\")\\n\\n    # Store the trained models and their mean ROC AUC scores in the dictionary\\n    models[target_class] = {\\'xgb_model\\': xgb_model, \\'xgb_roc_auc\\': mean_xgb_roc_auc,\\n                             \\'lgb_model\\': lgb_model, \\'lgb_roc_auc\\': mean_lgb_roc_auc}\\n\\n# Calculate weights based on mean ROC AUC scores\\nweights = {}\\nfor target_class in target_classes:\\n    xgb_weight = models[target_class][\\'xgb_roc_auc\\'] / (models[target_class][\\'xgb_roc_auc\\'] + models[target_class][\\'lgb_roc_auc\\'])\\n    lgb_weight = 1 - xgb_weight\\n    weights[target_class] = {\\'xgb\\': xgb_weight, \\'lgb\\': lgb_weight}\\n\\n# Ensemble the models\\nensemble_models = {}\\nfor target_class in target_classes:\\n    xgb_model = models[target_class][\\'xgb_model\\']\\n    lgb_model = models[target_class][\\'lgb_model\\']\\n    ensemble_model = VotingClassifier(estimators=[(\\'xgb\\', xgb_model), (\\'lgb\\', lgb_model)], \\n                                      voting=\\'soft\\', \\n                                      weights=[weights[target_class][\\'xgb\\'], weights[target_class][\\'lgb\\']])\\n    ensemble_models[target_class] = ensemble_model\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%capture\n",
    "def train_xgb_model(X_train, X_test, y_train, y_test, params):\n",
    "    # Initialize XGBoost classifier with given parameters\n",
    "    xgb_model = XGBClassifier(**params)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities for the positive class on the test data\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    return xgb_model, roc_auc\n",
    "\n",
    "def train_lgb_model(X_train, X_test, y_train, y_test, params):\n",
    "    # Initialize LightGBM classifier with given parameters\n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities for the positive class on the test data\n",
    "    y_pred_proba = lgb_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    return lgb_model, roc_auc\n",
    "\n",
    "# Define a dictionary to store the trained models and their ROC AUC scores\n",
    "models = {}\n",
    "\n",
    "# Train models for each target class\n",
    "for target_class in target_classes:\n",
    "    print(f\"Training models for {target_class}...\")\n",
    "\n",
    "    # Get best parameters for XGBoost and LightGBM for the current target class\n",
    "    best_params_xgb_target = best_params_xgb.get(target_class, {})\n",
    "    best_params_xgb_target['enable_categorical'] = True\n",
    "    best_params_lgb_target = best_params_lgb.get(target_class, {})\n",
    "    best_params_lgb_target['enable_categorical'] = True\n",
    "\n",
    "    # Initialize RepeatedStratifiedKFold\n",
    "    kf = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)\n",
    "    \n",
    "    # Initialize lists to store the scores for each fold\n",
    "    xgb_roc_auc_scores = []\n",
    "    lgb_roc_auc_scores = []\n",
    "\n",
    "    # Split the data using StratifiedKFold\n",
    "    for train_index, test_index in kf.split(X, y[target_class]):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[target_class].iloc[train_index], y[target_class].iloc[test_index]\n",
    "\n",
    "        # Train XGBoost model for the current target class\n",
    "        xgb_model, xgb_roc_auc = train_xgb_model(X_train, X_test, y_train, y_test, best_params_xgb_target)\n",
    "        xgb_roc_auc_scores.append(xgb_roc_auc)\n",
    "\n",
    "        # Train LightGBM model for the current target class\n",
    "        lgb_model, lgb_roc_auc = train_lgb_model(X_train, X_test, y_train, y_test, best_params_lgb_target)\n",
    "        lgb_roc_auc_scores.append(lgb_roc_auc)\n",
    "\n",
    "    # Calculate the mean ROC AUC scores across all folds\n",
    "    mean_xgb_roc_auc = np.mean(xgb_roc_auc_scores)\n",
    "    mean_lgb_roc_auc = np.mean(lgb_roc_auc_scores)\n",
    "\n",
    "    print(f\"Mean XGBoost ROC AUC for {target_class}: {mean_xgb_roc_auc}\")\n",
    "    print(f\"Mean LightGBM ROC AUC for {target_class}: {mean_lgb_roc_auc}\")\n",
    "\n",
    "    # Store the trained models and their mean ROC AUC scores in the dictionary\n",
    "    models[target_class] = {'xgb_model': xgb_model, 'xgb_roc_auc': mean_xgb_roc_auc,\n",
    "                             'lgb_model': lgb_model, 'lgb_roc_auc': mean_lgb_roc_auc}\n",
    "\n",
    "# Calculate weights based on mean ROC AUC scores\n",
    "weights = {}\n",
    "for target_class in target_classes:\n",
    "    xgb_weight = models[target_class]['xgb_roc_auc'] / (models[target_class]['xgb_roc_auc'] + models[target_class]['lgb_roc_auc'])\n",
    "    lgb_weight = 1 - xgb_weight\n",
    "    weights[target_class] = {'xgb': xgb_weight, 'lgb': lgb_weight}\n",
    "\n",
    "# Ensemble the models\n",
    "ensemble_models = {}\n",
    "for target_class in target_classes:\n",
    "    xgb_model = models[target_class]['xgb_model']\n",
    "    lgb_model = models[target_class]['lgb_model']\n",
    "    ensemble_model = VotingClassifier(estimators=[('xgb', xgb_model), ('lgb', lgb_model)], \n",
    "                                      voting='soft', \n",
    "                                      weights=[weights[target_class]['xgb'], weights[target_class]['lgb']])\n",
    "    ensemble_models[target_class] = ensemble_model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e6fa69b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:16.134086Z",
     "iopub.status.busy": "2024-03-24T06:19:16.133561Z",
     "iopub.status.idle": "2024-03-24T06:19:16.142814Z",
     "shell.execute_reply": "2024-03-24T06:19:16.141411Z"
    },
    "papermill": {
     "duration": 0.02565,
     "end_time": "2024-03-24T06:19:16.145682",
     "exception": false,
     "start_time": "2024-03-24T06:19:16.120032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Calculate feature importance\\nfor target_class in target_classes:\\n    print(f\"Feature importance for {target_class}:\")\\n    \\n    # XGBoost feature importance\\n    xgb_importance = permutation_importance(models[target_class][\\'xgb_model\\'], X_test, y_test, scoring=\\'roc_auc\\', n_repeats=30, random_state=42)\\n    xgb_feature_importance = pd.DataFrame({\\'Feature\\': X.columns, \\'Importance\\': xgb_importance.importances_mean})\\n    xgb_feature_importance = xgb_feature_importance.sort_values(by=\\'Importance\\', ascending=False)\\n    print(\"XGBoost Model:\")\\n    print(xgb_feature_importance)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Calculate feature importance\n",
    "for target_class in target_classes:\n",
    "    print(f\"Feature importance for {target_class}:\")\n",
    "    \n",
    "    # XGBoost feature importance\n",
    "    xgb_importance = permutation_importance(models[target_class]['xgb_model'], X_test, y_test, scoring='roc_auc', n_repeats=30, random_state=42)\n",
    "    xgb_feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': xgb_importance.importances_mean})\n",
    "    xgb_feature_importance = xgb_feature_importance.sort_values(by='Importance', ascending=False)\n",
    "    print(\"XGBoost Model:\")\n",
    "    print(xgb_feature_importance)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed722df",
   "metadata": {
    "papermill": {
     "duration": 0.012355,
     "end_time": "2024-03-24T06:19:16.170813",
     "exception": false,
     "start_time": "2024-03-24T06:19:16.158458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bef31504",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:16.199722Z",
     "iopub.status.busy": "2024-03-24T06:19:16.199156Z",
     "iopub.status.idle": "2024-03-24T06:19:16.208804Z",
     "shell.execute_reply": "2024-03-24T06:19:16.207031Z"
    },
    "papermill": {
     "duration": 0.029013,
     "end_time": "2024-03-24T06:19:16.212791",
     "exception": false,
     "start_time": "2024-03-24T06:19:16.183778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%capture\\n# Define a dictionary to store the predictions for each target class\\npredictions = {}\\n\\n# Predict on test data using ensemble models\\nfor target_class in target_classes:\\n    ensemble_model = ensemble_models[target_class]  # Get the ensemble model for the current target class\\n    ensemble_model.fit(X, y[target_class])\\n    y_pred_proba = ensemble_model.predict_proba(test)[:, 1]  # Predict probabilities for the positive class\\n    predictions[target_class] = y_pred_proba\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%capture\n",
    "# Define a dictionary to store the predictions for each target class\n",
    "predictions = {}\n",
    "\n",
    "# Predict on test data using ensemble models\n",
    "for target_class in target_classes:\n",
    "    ensemble_model = ensemble_models[target_class]  # Get the ensemble model for the current target class\n",
    "    ensemble_model.fit(X, y[target_class])\n",
    "    y_pred_proba = ensemble_model.predict_proba(test)[:, 1]  # Predict probabilities for the positive class\n",
    "    predictions[target_class] = y_pred_proba\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e1ea37a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:19:16.241283Z",
     "iopub.status.busy": "2024-03-24T06:19:16.240567Z",
     "iopub.status.idle": "2024-03-24T06:57:49.137269Z",
     "shell.execute_reply": "2024-03-24T06:57:49.135140Z"
    },
    "papermill": {
     "duration": 2312.917441,
     "end_time": "2024-03-24T06:57:49.141887",
     "exception": false,
     "start_time": "2024-03-24T06:19:16.224446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.21\" 2023-10-17; OpenJDK Runtime Environment (build 11.0.21+9-post-Ubuntu-0ubuntu120.04); OpenJDK 64-Bit Server VM (build 11.0.21+9-post-Ubuntu-0ubuntu120.04, mixed mode, sharing)\n",
      "  Starting server from /opt/conda/lib/python3.10/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpazr2_zlp\n",
      "  JVM stdout: /tmp/tmpazr2_zlp/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpazr2_zlp/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>06 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.44.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>3 months and 3 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_unknownUser_ku8pov</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.230 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.13 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------\n",
       "H2O_cluster_uptime:         06 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.44.0.3\n",
       "H2O_cluster_version_age:    3 months and 3 days\n",
       "H2O_cluster_name:           H2O_from_python_unknownUser_ku8pov\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.230 Gb\n",
       "H2O_cluster_total_cores:    1\n",
       "H2O_cluster_allowed_cores:  1\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.13 final\n",
       "--------------------------  ----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: || (done) 100%\n",
      "Parse progress: || (done) 100%\n",
      "Parse progress: || (done) 100%\n",
      "Training AutoML model for Pastry...\n",
      "AutoML progress: || (done) 100%\n",
      "stackedensemble prediction progress: || (done) 100%\n",
      "Export File progress: || (done) 100%\n",
      "Training AutoML model for Z_Scratch...\n",
      "AutoML progress: || (done) 100%\n",
      "stackedensemble prediction progress: || (done) 100%\n",
      "Export File progress: || (done) 100%\n",
      "Training AutoML model for K_Scatch...\n",
      "AutoML progress: || (done) 100%\n",
      "stackedensemble prediction progress: || (done) 100%\n",
      "Export File progress: || (done) 100%\n",
      "Training AutoML model for Stains...\n",
      "AutoML progress: || (done) 100%\n",
      "stackedensemble prediction progress: || (done) 100%\n",
      "Export File progress: || (done) 100%\n",
      "Training AutoML model for Dirtiness...\n",
      "AutoML progress: || (done) 100%\n",
      "stackedensemble prediction progress: || (done) 100%\n",
      "Export File progress: || (done) 100%\n",
      "Training AutoML model for Bumps...\n",
      "AutoML progress: || (done) 100%\n",
      "stackedensemble prediction progress: || (done) 100%\n",
      "Export File progress: || (done) 100%\n",
      "Training AutoML model for Other_Faults...\n",
      "AutoML progress: || (done) 100%\n",
      "stackedensemble prediction progress: || (done) 100%\n",
      "Export File progress: || (done) 100%\n",
      "H2O session _sid_b178 closed.\n"
     ]
    }
   ],
   "source": [
    "# Import H2O\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "h2o.init()\n",
    "\n",
    "train_h2o = h2o.import_file('/kaggle/input/playground-series-s4e3/train.csv')\n",
    "test_h2o = h2o.import_file('/kaggle/input/playground-series-s4e3/test.csv')\n",
    "faults_h2o = h2o.import_file('/kaggle/input/faulty-steel-plates/faults.csv')\n",
    "\n",
    "# Remove 'id' column from train and test DataFrames\n",
    "train_h2o = train_h2o.drop(\"id\", axis=1)\n",
    "test_h2o = test_h2o.drop(\"id\", axis=1)\n",
    "\n",
    "# Calculate the sum of target classes for each row\n",
    "row_sums = train_h2o[target_classes].sum(axis=1)\n",
    "\n",
    "# Filter out rows where the sum is greater than 1 or equal to 0\n",
    "filtered_train = train_h2o[(row_sums > 0) & (row_sums <= 1)]\n",
    "\n",
    "# Specify if dataset is synthetically generated\n",
    "train_h2o['generated'] = 1\n",
    "faults_h2o['generated'] = 0\n",
    "test_h2o['generated'] = 1\n",
    "\n",
    "# Concatenate faults DataFrame with train DataFrame\n",
    "train_h2o = train_h2o.rbind(faults_h2o)\n",
    "train_h2o[target_classes] = train_h2o[target_classes].asfactor()\n",
    "\n",
    "# Define a dictionary to store predictions\n",
    "predictions_dict = {}\n",
    "\n",
    "# Loop through each target class\n",
    "for target_class in target_classes:\n",
    "    print(f\"Training AutoML model for {target_class}...\")\n",
    "\n",
    "    # Extract features (X) for the current target class\n",
    "    X_h2o = train_h2o.columns[:-8]  # Assuming the last 8 columns are the target classes\n",
    "\n",
    "    # Train AutoML model with ROC AUC as stopping metric\n",
    "    aml = H2OAutoML(max_models=10, seed=42, stopping_metric='AUC')\n",
    "    aml.train(x=X_h2o, y=target_class, training_frame=train_h2o)\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = aml.leader\n",
    "\n",
    "    # Predict probabilities for the test dataset\n",
    "    predictions = best_model.predict(test_h2o)\n",
    "\n",
    "    # Save predictions to the dictionary\n",
    "    predictions_dict[target_class] = predictions.as_data_frame()\n",
    "\n",
    "# Stop H2O cluster\n",
    "h2o.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43172929",
   "metadata": {
    "papermill": {
     "duration": 0.034212,
     "end_time": "2024-03-24T06:57:49.211433",
     "exception": false,
     "start_time": "2024-03-24T06:57:49.177221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b427f182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:57:49.283020Z",
     "iopub.status.busy": "2024-03-24T06:57:49.282539Z",
     "iopub.status.idle": "2024-03-24T06:57:49.289339Z",
     "shell.execute_reply": "2024-03-24T06:57:49.288330Z"
    },
    "papermill": {
     "duration": 0.0466,
     "end_time": "2024-03-24T06:57:49.291875",
     "exception": false,
     "start_time": "2024-03-24T06:57:49.245275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p1_values = {}\n",
    "\n",
    "for target_class in target_classes:\n",
    "    # Select the dataframe corresponding to the target class\n",
    "    df_target_class = predictions_dict[target_class]\n",
    "    \n",
    "    # Extract the p0 values from the dataframe\n",
    "    p1_values[target_class] = df_target_class['p1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f3984af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T06:57:49.361659Z",
     "iopub.status.busy": "2024-03-24T06:57:49.361180Z",
     "iopub.status.idle": "2024-03-24T06:57:49.645202Z",
     "shell.execute_reply": "2024-03-24T06:57:49.643695Z"
    },
    "papermill": {
     "duration": 0.321685,
     "end_time": "2024-03-24T06:57:49.647817",
     "exception": false,
     "start_time": "2024-03-24T06:57:49.326132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19219</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19220</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19221</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19222</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19223</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Pastry  Z_Scratch  K_Scatch  Stains  Dirtiness  Bumps  Other_Faults\n",
       "0  19219    0.47       0.00      0.00    0.00       0.01   0.15          0.34\n",
       "1  19220    0.30       0.01      0.01    0.00       0.15   0.16          0.37\n",
       "2  19221    0.00       0.04      0.05    0.00       0.01   0.26          0.48\n",
       "3  19222    0.16       0.00      0.00    0.01       0.00   0.48          0.48\n",
       "4  19223    0.00       0.00      0.00    0.00       0.00   0.66          0.39"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(p1_values)\n",
    "submission.insert(0, \"id\", sample_submission[\"id\"])\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e549b85",
   "metadata": {
    "papermill": {
     "duration": 0.033664,
     "end_time": "2024-03-24T06:57:49.716235",
     "exception": false,
     "start_time": "2024-03-24T06:57:49.682571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7659021,
     "sourceId": 68699,
     "sourceType": "competition"
    },
    {
     "datasetId": 2363,
     "sourceId": 3972,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2347.194046,
   "end_time": "2024-03-24T06:57:51.587308",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-24T06:18:44.393262",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
